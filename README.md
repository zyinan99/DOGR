# DOGR

*Towards Versatile Visual Document Grounding and Referring*

Yinan Zhou*, Yuxin Chen*, Haokun Lin,Shuyu Yang, Li Zhu, Zhongang Qi‡, Chen Ma‡, Ying Shan

*Equal Contribution †Project Lead ‡Corresponding Authors 

 <a href='https://github.com/Tencent/DOGR'>DOGR is Redirected to this Repo</a> &nbsp;

 <a href='https://zyinan99.github.io/'><img src='https://img.shields.io/badge/Project-Page-Green'></a> &nbsp;
 <a href="https://arxiv.org/pdf/2411.17125"><img src="https://img.shields.io/static/v1?label=Arxiv Preprint&message=DOGE&color=red&logo=arxiv"></a>
 <a href="https://www.youtube.com/watch?v=gfhF3oYH178&feature=youtu.be"><img src="https://img.shields.io/static/v1?label=Demo&message=Video&color=orange&logo=youtube"></a>

 The constructed traning data, test data and DOGE-Bench files can be found in <a href='https://huggingface.co/datasets/yinanzhou1/doge_data'>DOGR Data</a> &nbsp;

### DOGR Bench Data
DOGR-Bench files can be downloaded here(https://huggingface.co/datasets/yinanzhou1/DOGR_Bench)
 ### Video
[Watch the introduction video here!](https://www.youtube.com/watch?v=gfhF3oYH178&feature=youtu.be) 


 ### Demo
  To be released.

  
### Citation

```
@misc{zhou2024dogeversatilevisualdocument,
      title={DOGE: Towards Versatile Visual Document Grounding and Referring}, 
      author={Yinan Zhou and Yuxin Chen and Haokun Lin and Shuyu Yang and Li Zhu and Zhongang Qi and Chen Ma and Ying Shan},
      year={2024},
      eprint={2411.17125},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2411.17125}, 
}
}
```
Please refer to our [license file](https://github.com/zyinan99/DOGR/blob/main/LICENSE) for more details.
